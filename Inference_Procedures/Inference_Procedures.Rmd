---
title: "Inference Procedures"
subtitle: "Statistics with R"
author: DragonflyStats.github.io
output:
  prettydoc::html_pretty:
    theme: cayman
    highlight: github
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
options(digits=3)
```

Inference Procedures
==============================

#### Key Points:

* The two main types of inference procedures are \textbf{Hypothesis Tests} and \textbf{Confidence Intervals}. You are expected to be familiar with both.

* There are two ways of conducting a hypothesis test. One method is to compute the test statistic, and compare to the critical values.

* The second method is to compute the probability value  (i.e. p-value), and compare it to the significance level. Nearly all computer programs use the p-value approach. In this course we will focus on the p-value approach.


### Significance Level}

In hypothesis testing, the significance level is the criterion used for rejecting the null hypothesis. The significance level is used in hypothesis testing as follows: First, the difference between the results of the experiment and the null hypothesis is determined. Then, assuming the null hypothesis is true, the probability of a difference that large or larger is computed . Finally, this probability is compared to the significance level. If the probability is less than or equal to the significance level, then the null hypothesis is rejected and the outcome is said to be statistically significant.

Traditionally, experimenters have used either the 0.05 level (sometimes called the $5\%$ level) or the 0.01 level ($1\%$ level), although the choice of levels is largely subjective. The lower the significance level, the more the data must diverge from the null hypothesis to be significant.
 Therefore, the 0.01 level is more conservative than the 0.05 level. The Greek letter alpha ($\alpha$) is sometimes used to indicate the significance level

### The probability value }

The probability value (sometimes called the $p-value$) is the probability of obtaining a statistic as different from or more different from the parameter specified in the null hypothesis as the statistic obtained in the experiment.

#### The precise meaning of the p-value}

There is often confusion about the precise meaning of the probability computed in a significance test. The convention in hypothesis testing is that the null hypothesis (Ho) is assumed to be true.

The difference between the statistic computed in the sample and the parameter specified by the null hypothesis is computed and the probability of obtaining a difference this large or large is calculated. This probability value is the probability of obtaining data as extreme or more extreme than the current data (assuming the null hypothesis is true).

It is not the probability of the null hypothesis itself. Thus, if the probability value is 0.005, this does not mean that the probability that the null hypothesis is either true or false is 0.005. It means that the probability of obtaining data as different or more different from the null hypothesis as those obtained in the experiment is 0.005.

The inferential step to conclude that the null hypothesis is false goes as follows: The data (or data more extreme) are very unlikely given that the null hypothesis is true.
This means that:

(1) a very unlikely event occurred or

(2) the null hypothesis is false.

The inference usually made is that the null hypothesis is false.  (Importantly it doesn't prove the null hypothesis to be false)

### Using p-values to reject the null hypothesis

* According to one view of hypothesis testing, the significance level should be specified before any statistical calculations are performed. Then, when the p-value is computed from a significance test, it is compared with the significance level.

* The null hypothesis is rejected if p-value is at or below the significance level; it is not rejected if p-value is above the significance level. The degree to which p ends up being above or below the significance level does not matter.The null hypothesis either is or is not rejected at the previously stated significance level.

* Thus, if an experimenter originally stated that he or she was using the Î± = 0.05 significance level and p-value was subsequently calculated to be 0.042, then the person would reject the null hypothesis at the 0.05 level. If p-value had been 0.0001 instead of 0.042 then the null hypothesis would still be rejected at the 0.05 significance level.

* The experimenter would not have any basis to be more confident that the null hypothesis was false with a p-value of 0.0001 than with a p-value of 0.041. Similarly, if the p had been 0.051 then the experimenter would fail to reject the null hypothesis

* The experimenter would have no more basis to doubt the validity of the null hypothesis than if p-value had been 0.482. The conclusion would be that the null hypothesis could not be rejected at the 0.05 level.

* In short, this approach is to specify the significance level in advance and use p-value only to determine whether or not the null hypothesis can be rejected at the stated significance level.

* Many statisticians and researchers find this approach to hypothesis testing not only too rigid, but basically illogical. It is very reasonable to  have more confidence that the null hypothesis is false with a p-value of 0.0001 then with a p-value of 0.042?

* The less likely the obtained results (or more extreme results) under the null hypothesis, the more confident one should be that the null hypothesis is false.

* The null hypothesis should not be rejected once and for all. The possibility that it was falsely rejected is always present, and, all else being equal, the lower the p-value, the lower this possibility.

* According to this view, research reports should not contain the p-value, only whether or not the values were significant (at or below the significance level).

* However it is much more reasonable to just report the p-values. That way each reader can make up their mind about just how convinced they are that the null hypothesis is false.

#### Guidelines for Data Project}
For this module, as a rule of thumb, we will use the threshold of 0.01 for rejecting the null hypothesis. If the p-value is less than 0.01 we reject the null hypothesis. If it is greater than 0.05, we fail to reject the null hypothesis. If between the two, consider it to be a `grey area'. (i.e. suggest that more data is needed).

If the p-value is greater than 0.1 we would never reject the null hypothesis.
 
* Greater than 0.05 - Fail to reject Ho
* Less than 0.01 - Reject Ho
* Between 0.01 and 0.05 - advise that it is close to both conclusions.



%### Probability Values}
%The probability of getting a values as extreme or more as some statistic, such as sum or mean, is known as a p-value. When performing statistical calculations using computer software they are the most commonly used item for making statistical decisions.
%
%In this last instance, we would usually fail to reject the null hypothesis.

Many \texttt{R} outputs will give a group of asterisks beside the data to help the user in interpreting the data, depending on how significant the result is.

<pre><code>
p-value  < 0.0001  	***
p-value  < 0.001	**
p-value  < 0.01	*
p-value  < 0.1
</code></pre>


### Sample Size}
For Student's $t$ distribution, statistical tables such (e.g. Murdoch Barnes and State Examinations Commission tables) only tabulate quantiles with degrees of freedom of less than 30. This restraint has given rise to the convention that a sample of size greater than 30 is a `large sample' and in this case the standard normal distribution should be used.

However there is a disparity between the $Z$ value and the correct $t$ value. For a sample size of 61 (i.e. degrees of freedom =60), the $97.5\%$ t-quantiles of Student's t distribution is 2.003, and not 1.96.

However, statistical software is free from this restraint. The correct distribution will be automatically used. The Student's $t$ distribution will be used in all appropriate cases. As the sample size increases the Student $t$ distribution converges with the standard normal distribution.

### Commonly Used Inference Procedures}

*    Hypothesis test for the mean of a single sample
*    Hypothesis test for the mean of two independent samples
*    Hypothesis test for the proportion of a single group
*    Hypothesis test for the proportions of two independent samples

