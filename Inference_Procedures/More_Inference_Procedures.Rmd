

## Part 2 More inference procedures}
### Formal tests for Normality}


*  ad.test for outliers Anderson Darling test
*  shapiro Wilk test for normality
*  ks.test for distributions (Kolmogorov Smirnov test)
*  grubbs test for outliers
*  chi square test



useful for categorical data. Consider a two by two contingency table.


apropos test to find other tests available in R. Chi-squared Test of Independence

Two random variables x and y are called independent if the probability distribution of one variable is not affected by the presence of another.

Assume fij is the observed frequency count of events belonging to both i-th category of xand j-th category of y. Also assume eij to be the corresponding expected count if x and yare independent. The null hypothesis of the independence assumption is to be rejected if the p-value of the following Chi-squared test statistics is less than a given significance level α.



Example

 Graphical procedures for assessing normality

qqplot

histograms


### Quantile-Quantile Plots}

Description

qqnorm is a generic function the default method of which produces a normal QQ plot of the values in y. qqline adds a line to a normal quantile-quantile plot which passes through the first and third quartiles.

qqplot produces a QQ plot of two datasets.

Graphical parameters may be given as arguments to qqnorm, qqplot and qqline.

----------------------------------------------------------


Part 3 linear model

scatterplots


### Scatter Plot:}

 A scatter plot of two variables shows the values of one variable on the Y axis and the values of the other variable on the X axis. Scatter plots are well suited for revealing the relationship between two variables. The scatter plot shown in Figure 4 illustrates data from one of Galileo's classic experiments in which he observed the distance traveled balls traveled after being dropped on a incline as a function of their release height.



A standard practice when performing a bivariate analysis is to construct a scatter plot. This is easily implementable using the R command plot.

Note that the predictor variable precedes the response variable.

More complex scatterplots, with better visual appeal, can be constructed. We will lok at this more later on in the semester.


The Pearson product-moment correlation coefficient is a measure of the strength of the linear relationship between two variables. It is referred to as Pearson's correlation or simply as the correlation coefficient. If the relationship between the variables is not linear, then the correlation coefficient does not adequately represent the strength of the relationship between the variables.

The symbol for Pearson's correlation is "ρ" when it is measured in the population and "r" when it is measured in a sample. Because we will be dealing almost exclusively with samples, we will use r to to represent Pearson's correlation unless otherwise noted.

Pearson's r can range from -1 to 1. An r of -1 indicates a perfect negative linear relationship between variables, an r of 0 indicates no linear relationship between variables, and an r of 1 indicates a perfect positive relationship between variables. 


%% - http://onlinestatbook.com/chapter4/intro.html
